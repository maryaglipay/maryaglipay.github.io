[
  {
    "objectID": "research.html",
    "href": "research.html",
    "title": "maryaglipay.github.io",
    "section": "",
    "text": "This is a Quarto website. Hello!\nTo learn more about Quarto websites visit https://quarto.org/docs/websites."
  },
  {
    "objectID": "posts/blog1/index.html",
    "href": "posts/blog1/index.html",
    "title": "Test Negative Studies: Let’s Talk About It",
    "section": "",
    "text": "If you’ve been keeping up with the Covid-19 vaccine literature, there may be a study design that sticks out to you: a test-negative study. Huh? What’s that?\nBefore we get into what a test negative study is, let’s think about what these vaccine effectiveness studies want to examine. The exposure in these studies is typically vaccination status (0,1,2 doses, typically with 0 as the referent category), and the outcome is SARS-CoV-2 infection. The question is, what is the real-world impact of vaccines on SARS-CoV-2 infection?\nBut back up–why do we need to know real-world effectiveness of vaccines? Don’t we have RCT data on how well the vaccines work? Yes, we do- but these RCTs typically have very stringent inclusion criteria (children have to be very healthy, etc.), and the families that self-select into these studies tend to be very affluent, well-connected, educated. Moreover, RCTs tend to have very regimented follow-up and dosing—families are reminded that they need to come in for their second dose, an RCT coordinator makes sure they receive it, vaccine administration is highly protocol-ized (vaccine expiration and storage are well-monitored). In the real world, it doesn’t always happen this way. You’ve got kids who are maybe not the healthiest–they might have chronic conditions like asthma. Families aren’t always rich and educated. Families may not come for their second dose, or may not come on time. Vaccine distribution is challenging, with changes in expiry and variable storage abilities. If we want to make inference to a population that deals with these system-level challenges, that has some health conditions, that are not as rich/well connected, then we need to do real-world effectiveness studies.\nOk, so how do we do this? In an ideal world, we could conduct a prospective cohort study—recruit children, follow them up over time, surveil them daily to see who got infected with SARS-CoV-2 and when. Sounds simple right? The problem is that this is really, really resource intensive. You need to follow a lot of children to have precise estimates. You need to test these children every day, and even if you tested them weekly, this can mean thousands upon thousands of PCR tests. You might have hard time finding families/children who are willing to do this.\nOk. So cohort studies are too expensive. What the next best thing? The next best thing might be a population-based case control study. Here we would have complete case ascertainment, and we would select a random sample of population controls. This study, in essence, could be viewed as nested within the cohort, with missing data (i.e. controls we did not select) as missing at random. In other words, according to Sullivan, this would be a cohort study in which the statum of people who do not test are ignored. This study would be much cheaper, as we wouldn’t have to do hundreds of thousands of PCR tests. But population controls are challenging—the way that they are ascertained might be different from the way cases as ascertained. The population controls might be very different than the cases. In our scenario, cases are ascertained through testing centres or pharmacies or other places that do PCR tests. These people might have better access to healthcare than the general population. This means the cases and conrols will be non-exchangeable–there are confounding factors that will impact case ascertainment as well as vaccination status, meaning there will be bias.\nOK. What about a case-control study with ‘other’ patient controls–i.e. people who can access the testing centres and pharmacies. Now we’re onto something. These controls are more like our cases—there is some indirect matching going on here. This brings us to the test-negative study. A test-negative study recruit participants who attend Covid assessment centres and test positive for Covid-19; controls are participants who undergo the same tests for the same reasons as the cases, but test negative.\nThe advantage of test-negative studies is that they have similar participation rates between cases and controls, similar information quality and completeness, and similar access. A particular advantage of test-negative studies is that they compare individuals with similar health seeking-behaviour and access to testing. We might imagine that a person who is more likely to seek vaccines is probably also more likely to find a way to get a PCR test. This is especially important given testing restrictions, which excluded many individuals from obtaining a test after December 2021. Residual confounding might also be less of a concern in test negative studies because (see Shi et al) variables that impact vaccination status are similar for Covid-19 and non-Covid-19 respiratory infections (e.g. children with parents who are healthcare workers might be more likely to get the vaccine, but the proportion of children with healthcare workers who have Covid-19 versus some other respiratory infection is probably the same).\nSome people have had been critical of test-negative designs. Westreich et al. state that test-negative designs are not really case-control studies as controls are not formally sampled from the source population. However, as Vandenbroucke and Pearce point out, there is a broad class of case control studies that use ‘other’ patient controls, which can sometimes help with exchangeability between the cases and controls. These designs using ‘other’ patient controls can provide valid estimates when (according to Jackson and Nelson) a) other respiratory viruses are not impacted by the vaccine and b) vaccine effectiveness does not vary by health-care seeking behaviour.\nOthers have asserted that a test-negative study is a cohort study with some incomplete follow-up. However, there is no follow-up happening in test negative designs because case and control status are ascertained at a single point in time: the time of the test (Vandenbrocke and Pearce).\nHowever, under the assumption of no confounding, selection bias, misclassification and assuming parametric assumptions are met, the test-negative study can provide valid estimates of vaccine effectiveness."
  },
  {
    "objectID": "posts/blog1/blog2.html",
    "href": "posts/blog1/blog2.html",
    "title": "Who are your controls in test-negative studies?",
    "section": "",
    "text": "One thing that comes up in test-negative studies is, who exactly are the controls? Repeat after me: your controls are participants in your study who tested negative. If you’ve been working with cohort data or RCT data a lot, this is not intuitive: we often think in terms of exposed and unexposed. Controls are not your unexposed; they are those who tested negative.\nThe overall test effectiveness study will just compare those who test positive with those who test negative, full stop. [Note: you’ll still have to adjust for calendar date, because what might happen is that perhaps as the pandemic rolls on, as we change seasons, people are more likely to get vaccinated and also perhaps more likely to test positive. This biases the result toward the null]\nWe can do interval analysis too-e.g., what is the vaccine effectiveness, or impact of vaccines, on children who were vaccinated only 14-29 days prior to their index date (remember that the index date is the day that they take their test). Another way of phrasing it is, what is the vaccine effectiveness 14-29 days after vaccination?\nIn interval analysis, who are the controls? Again, they are still children who tested negative in that interval. How to know if they are in the interval? For vaccinated test-negatives (controls), you’ll have an ‘interval date’, which tells you how along ago vaccination happened. In our example, you’ll select vaccinated controls who vaccinated 14-29 days before their index date. For unvaccinated control, this interval date doesn’t really make any sense. From which date should we count the unvaccinated control (or case for that matter)?\nRemember our time zero is July 28, 2022 (when Ontario rolled out vaccines for children in this age group). We can calculate a ‘time interval’ for unvaccinated children between their index date and this date.\nTake for example, the stratified/interval analysis in children who tested 14-29 days ago. Let’s make a 2x2 table below.\n\n\n\n\n\n\n\n\n\nTest negative\nTest positive\n\n\n\n\nUnvaccinated\nUnvaccinated 14-29 days ago\nUnvaccinated 14-29 days ago.\n\n\nVaccinated\nVaccinated 14-29 days ago\nVaccinated 14-29 days ago\n\n\n\nWe should be looking at everyone 14-29 days prior to their index date, or 14-29 days ‘after vaccination’- but for the unvaccinated, ‘after vaccination’ doesn’t make sense because they were never vaccinated. But we can look at the interval between the roll-out date and their index date. As long as it was greater than 14-29 days, they can be considered. An index date that happened 90 days after roll-out for the unvaccinated can be included in the comparison of 14-29 days, because unvaccinated at 90 days also means unvaccinated at 60 days, and unvaccinated at 30 days. That means we can include everyone who is unvaccinated at an index date greater than the interval we are interested in, in our analysis, whether they are test negative or test positive.\nOther notes:\nLet’s talk about ‘follow-up,’ which is a bit of a tricky concept. Note that we can’t really talk about ‘incomplete’ or ‘complete’ follow-up in this analysis because outcome ascertainment happens at one point in time: the time of the test (see last paragraph in this blog post). But there is kind of a follow-up time for the vaccinated group, the time from vaccination to the index date; in the unvaccinated group, the ‘follow-up’ time is a bit arbitrary—it’s counted from time zero, date of vaccine rollout in Ontario. But remember, a person who is unvaccinated at their index date, which happens, for example, 90 days after time zero, is also unvaccinated at time 60, time 30.\nWhat about someone who with multiple tests–they tested negative at 1, then tested positive at another, and they changed their vaccine status during that time? Remember that our ‘anchor’ is the index date, the date that someone tested. For our analysis, among cases, we will take the first positive event. For controls (test negative), we will randomly sample the index date/case. The random sampling will be non-differential between the vaccinated and unvaccinated.\nBut why not compare cases with controls that have the same index date? People with the same index date are comparable in terms of the day-to-day pandemic context that gave rise to their testing. What is being suggested here is that we match cases and controls with the same index date. The issue is that it might be hard to find a control for every case. But matching could be considered to enhance the comparability."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Mary Aglipay",
    "section": "",
    "text": "PhD Epidemiology Student, Dalla Lana School of Public Health, University of Toronto"
  },
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "maryaglipay.github.io",
    "section": "",
    "text": "Test Negative Studies: Let’s Talk About It\n\n\n\n\n\n\n\n\n\n\n\n\nNov 28, 2022\n\n\n\n\n\n\n\n\nWho are your controls in test-negative studies?\n\n\n\n\n\n\n\n\n\n\n\n\nNov 29, 2022\n\n\n\n\n\n\nNo matching items"
  }
]